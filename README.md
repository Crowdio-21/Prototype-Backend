# Tests

This folder contains utility scripts for testing and running the CrowdCompute system.

## Scripts
 

### `run_foreman_simple.py`
Start the FastAPI foreman server.
```bash
python run_foreman_simple.py
```

### `run_worker_simple.py`
Start a FastAPI worker server.
```bash
python run_worker_simple.py
```

### `run_multiple_workers.py`
Launch multiple worker servers simultaneously for distributed processing.
```bash
# Default: Launch 8 workers
python run_multiple_workers.py

# Launch specific number of workers
python run_multiple_workers.py 8

# Custom starting port
python run_multiple_workers.py 8 --start-port 8001
```

**Features:**
- Starts multiple workers in parallel using asyncio
- Each worker gets a unique ID and consecutive port number
- All workers connect to the same foreman
- Ideal for testing distributed workloads

### `example_client.py`
Example client script demonstrating CrowdCompute usage.
```bash
python example_client.py <foremanIPaddress>
```

### `view_database.py`
View the contents of the SQLite database.
```bash
python view_database.py
```

### `quick_clear_db.py`
Quickly clear all data from the database.
```bash
python quick_clear_db.py
```

### `sentiment_analysis_pytorch_client.py`
Distributed sentiment analysis using PyTorch and HuggingFace transformers (DistilBERT). Demonstrates:
- Distributed NLP inference across multiple workers
- PyTorch-based transformer model execution
- Text splitting into sentences
- Task offloading and parallel processing
- Result aggregation with confidence-weighted scoring
```bash
python sentiment_analysis_pytorch_client.py <foremanIPaddress>
```

**Features:**
- Uses `distilbert-base-uncased-finetuned-sst-2-english` model
- Splits input text into sentences for parallel processing
- Each sentence analyzed independently on different workers
- Aggregates results with confidence-weighted sentiment scores
- Returns detailed per-sentence and overall sentiment analysis

**Requirements:**
```bash
pip install torch transformers
```

**Architecture Diagram:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          PYTORCH CLIENT                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Input Text: "I love this! Bad service. Great quality."         â”‚  â”‚
â”‚  â”‚              â†“ split_text_into_sentences()                      â”‚  â”‚
â”‚  â”‚  ["I love this!", "Bad service.", "Great quality."]             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â†“ distributed_map()                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            FOREMAN                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   Task 1     â”‚  â”‚   Task 2     â”‚  â”‚   Task 3     â”‚                 â”‚
â”‚  â”‚ "I love..."  â”‚  â”‚ "Bad serv..."â”‚  â”‚ "Great qu..."â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â†“                 â†“                  â†“                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“                 â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WORKER 1      â”‚ â”‚   WORKER 2      â”‚ â”‚   WORKER 3      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ PyTorch     â”‚ â”‚ â”‚ â”‚ PyTorch     â”‚ â”‚ â”‚ â”‚ PyTorch     â”‚ â”‚
â”‚ â”‚ DistilBERT  â”‚ â”‚ â”‚ â”‚ DistilBERT  â”‚ â”‚ â”‚ â”‚ DistilBERT  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â†“         â”‚ â”‚       â†“         â”‚ â”‚       â†“         â”‚
â”‚  ğŸ˜Š Positive    â”‚ â”‚  ğŸ˜¢ Negative    â”‚ â”‚  ğŸ˜Š Positive    â”‚
â”‚  conf: 0.98     â”‚ â”‚  conf: 0.85     â”‚ â”‚  conf: 0.92     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“                 â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RESULT AGGREGATION (CLIENT)                          â”‚
â”‚  Weighted Sentiment = (1.0Ã—0.98 + -1.0Ã—0.85 + 1.0Ã—0.92) / (0.98+0.85+0.92)â”‚
â”‚                     = 1.05 / 2.75 = 0.382 â†’ Slightly Positive          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**PyTorch Worker Processing Pipeline:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        WORKER EXECUTION FLOW                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  ğŸ“¥ Input: "I absolutely love this product!"
       â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  1. Load Model & Tokenizer              â”‚
  â”‚     - AutoTokenizer.from_pretrained()   â”‚
  â”‚     - AutoModelForSequenceClassificationâ”‚
  â”‚     - model.eval() [inference mode]     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  2. Tokenize Text                       â”‚
  â”‚     Input: "I absolutely love..."       â”‚
  â”‚     Output: {                           â”‚
  â”‚       'input_ids': [[101, 1045, ...]],  â”‚
  â”‚       'attention_mask': [[1,1,1,...]]   â”‚
  â”‚     }                                   â”‚
  â”‚     Shape: [1, seq_length]              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  3. PyTorch Inference                   â”‚
  â”‚     with torch.no_grad():               â”‚
  â”‚       outputs = model(**inputs)         â”‚
  â”‚     logits = outputs.logits             â”‚
  â”‚     Shape: [1, 2]                       â”‚
  â”‚     Values: [[-2.5], [3.2]]            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  4. Softmax & Classification            â”‚
  â”‚     probs = softmax(logits)             â”‚
  â”‚     = [0.002, 0.998]                    â”‚
  â”‚     predicted_class = argmax(probs) = 1 â”‚
  â”‚     confidence = max(probs) = 0.998     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
  ğŸ“¤ Output: {
       "sentiment": 1.0,
       "confidence": 0.998,
       "class_name": "positive",
       "neg_probability": 0.002,
       "pos_probability": 0.998,
       "logits": [-2.5, 3.2],
       "tensor_input_shape": [1, 35],
       "tensor_output_shape": [1, 2],
       "latency_ms": 1250,
       "model": "distilbert-base-uncased-finetuned-sst-2-english"
     }
```

**Tensor Transformation Diagram:**
```
TEXT â†’ TOKENS â†’ TENSORS â†’ MODEL â†’ LOGITS â†’ PROBABILITIES â†’ RESULT

"I love this!"
      â†“
[101, 1045, 2293, 2023, 999, 102]  â† Token IDs
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Tensor [1, 6]         â”‚
â”‚ [[101, 1045, 2293, ...]]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DistilBERT Model          â”‚
â”‚   (66M parameters)          â”‚
â”‚   6 layers, 768 dim         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Logits [1, 2]               â”‚
â”‚ [[-2.5, 3.2]]               â”‚
â”‚  â†‘NEG  â†‘POS                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ softmax(logits)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Probabilities [1, 2]        â”‚
â”‚ [[0.002, 0.998]]            â”‚
â”‚   â†‘NEG   â†‘POS               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ argmax + format
{
  "sentiment": 1.0,
  "confidence": 0.998,
  "class_name": "positive"
}
```

---

### `monte_carlo_euler_client.py`
Monte Carlo simulation to estimate Euler's number (e â‰ˆ 2.71828) using distributed workers. Demonstrates:
- Monte Carlo estimation using random sampling
- Parallel trial execution across multiple workers
- Statistical aggregation and error analysis
- Distributed computational mathematics

```bash
# Default: 1 million trials with 8 workers
python monte_carlo_euler_client.py

# Custom trials
python monte_carlo_euler_client.py 10000000

# Custom number of workers
python monte_carlo_euler_client.py 5000000 16

# Different foreman host
python monte_carlo_euler_client.py 1000000 8 192.168.1.100
```

**Mathematical Background:**
The algorithm generates random numbers uniformly in [0,1] and counts how many are needed until their sum exceeds 1. The expected count equals Euler's number e.

**Features:**
- Distributes Monte Carlo trials across multiple workers
- Calculates final estimate, absolute error, and error percentage
- Provides statistical summary (mean, std dev, min/max estimates)
- Performance metrics (throughput, latency, execution time)
- Worker-level result breakdown

**Example Output:**
```
ğŸ¯ Final Estimate of e: 2.7184512300
ğŸ“ True value of e:     2.7182818285
âŒ Absolute Error:      0.0001694015
ğŸ“‰ Error Percentage:    0.006232%

ğŸ“Š Statistical Summary:
   Workers completed:   8
   Total trials:        10,000,000
   Avg worker estimate: 2.7184512
   Std deviation:       0.002156
```

---

### `mcmc_bayesian_inference_client.py`
Markov Chain Monte Carlo (MCMC) for Bayesian parameter estimation using distributed workers. Demonstrates:
- Metropolis-Hastings MCMC algorithm
- Bayesian inference for normal distribution parameters (Î¼, Ïƒ)
- Multiple independent chains for convergence assessment
- Gelman-Rubin convergence diagnostics (RÌ‚ statistic)
- Posterior distributions with credible intervals

```bash
# Default: 4 chains, 10,000 iterations each
python mcmc_bayesian_inference_client.py

# Custom number of chains
python mcmc_bayesian_inference_client.py 8

# Custom iterations per chain
python mcmc_bayesian_inference_client.py 4 20000

# Different foreman host
python mcmc_bayesian_inference_client.py 4 10000 192.168.1.100
```

**Use Case:**
Estimates the mean (Î¼) and standard deviation (Ïƒ) of a normal distribution from observed data using Bayesian inference with uninformative priors.

**Features:**
- Metropolis-Hastings MCMC sampling algorithm
- Multiple independent chains run in parallel
- Burn-in period to discard initial transient samples
- Gelman-Rubin RÌ‚ convergence diagnostic (should be < 1.1)
- 95% posterior credible intervals
- Acceptance rate monitoring for tuning
- Per-chain and aggregated results

**Example Output:**
```
ğŸ¯ Posterior Distribution for Î¼ (mean):
   Estimate:       5.012345
   Std. Error:     0.198234
   95% CI:         [4.623412, 5.401234]
   True value:     5.000000

ğŸ“ˆ Convergence Diagnostics (Gelman-Rubin RÌ‚):
   RÌ‚ for Î¼:        1.0023 âœ… Converged
   RÌ‚ for Ïƒ:        1.0045 âœ… Converged
   Overall:        âœ… All chains converged

âš™ï¸  MCMC Statistics:
   Chains completed:     4
   Total samples:        40,000
   Avg acceptance rate:  35.24%
```

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MCMC CLIENT                            â”‚
â”‚  Observed Data: [5.2, 4.8, 5.1, 4.9, ...]                 â”‚
â”‚       â†“                                                     â”‚
â”‚  Create 4 independent chain configs                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ distributed_map()
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FOREMAN                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚Chain 0 â”‚  â”‚Chain 1 â”‚  â”‚Chain 2 â”‚  â”‚Chain 3 â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“           â†“           â†“           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚Worker 1â”‚  â”‚Worker 2â”‚  â”‚Worker 3â”‚  â”‚Worker 4â”‚
  â”‚MCMC    â”‚  â”‚MCMC    â”‚  â”‚MCMC    â”‚  â”‚MCMC    â”‚
  â”‚10k iterâ”‚  â”‚10k iterâ”‚  â”‚10k iterâ”‚  â”‚10k iterâ”‚
  â”‚Î¼â‰ˆ5.01  â”‚  â”‚Î¼â‰ˆ4.99  â”‚  â”‚Î¼â‰ˆ5.02  â”‚  â”‚Î¼â‰ˆ5.00  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“           â†“           â†“           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AGGREGATION & CONVERGENCE CHECK                   â”‚
â”‚  - Pool samples from all chains                            â”‚
â”‚  - Calculate Gelman-Rubin RÌ‚ statistic                     â”‚
â”‚  - Compute posterior means and credible intervals          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Usage

All scripts in this folder can be run directly from the `tests` directory. They automatically add the parent directory to the Python path to resolve imports.

## Typical Testing Workflow

### Basic Workflow
1. **Start Foreman:**
   ```bash
   python run_foreman_simple.py
   ```

2. **Start Worker (in another terminal):**
   ```bash
   python run_worker_simple.py
   ```

3. **Run Example Client (in another terminal):**
   ```bash
   python example_client.py localhost
   ```

### Distributed Computing Workflows

#### Sentiment Analysis with PyTorch
1. **Start Foreman**
2. **Start Multiple Workers:**
   ```bash
   python run_multiple_workers.py 4
   ```
3. **Run Sentiment Analysis:**
   ```bash
   python sentiment_analysis_pytorch_client.py
   ```

#### Monte Carlo Simulation
1. **Start Foreman**
2. **Start Multiple Workers:**
   ```bash
   python run_multiple_workers.py 8
   ```
3. **Run Monte Carlo Estimation:**
   ```bash
   python monte_carlo_euler_client.py 10000000
   ```

#### MCMC Bayesian Inference
1. **Start Foreman**
2. **Start Multiple Workers:**
   ```bash
   python run_multiple_workers.py 4
   ```
3. **Run MCMC Inference:**
   ```bash
   python mcmc_bayesian_inference_client.py 4 20000
   ```

### Utility Commands
4. **View Database (optional):**
   ```bash
   python view_database.py
   ```

5. **Clear Database (if needed):**
   ```bash
   python quick_clear_db.py
   ```
